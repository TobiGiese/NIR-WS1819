c(sum(exp(beta[1]+beta[2]*x)),
sum(exp(beta[1]+beta[2]*x)*x),
sum(exp(beta[1]+beta[2]*x)*x),
sum(exp(beta[1]+beta[2]*x)*x^2)),
2,2)
}
eps = 0.0001
repeat
{
beta_neu = beta_alt + solve(fisher(beta_alt)) %*% score(beta_alt)
if(sum((beta_neu-beta_alt)^2)/sum(beta_alt^2) < eps) break
beta_neu = beta_alt
}
repeat
{
beta_neu = beta_alt + solve(fisher(beta_alt)) %*% score(beta_alt)
if(sum((beta_neu-beta_alt)^2)/sum(beta_alt^2) < eps) break
beta_neu <- beta_alt
}
repeat
{
beta_neu = beta_alt + solve(fisher(beta_alt)) %*% score(beta_alt)
if(sum((beta_neu-beta_alt)^2)/sum(beta_alt^2) < eps) break
beta_neu <- beta_alt
beta_neu
}
repeat
{
beta_neu = beta_alt + solve(fisher(beta_alt)) %*% score(beta_alt)
if(sum((beta_neu-beta_alt)^2)/sum(beta_alt^2) < eps) break
beta_neu <- beta_alt
beta_neu
}
glm(species~1+logarea, data = gala.data)
glm(species~1+logarea, data = gala.data, family = poisson(link="log"))
glm1 = glm(species~1+logarea, data = gala.data, family = poisson(link="log"))
points(x, predict(gala.glm1), col= 2, pch = 16)
gala.glm1 = glm(species~1+logarea, data = gala.data, family = poisson(link="log"))
points(x, predict(gala.glm1), col= 2, pch = 16)
points(x, predict(exp(gala.glm1)), col= 2, pch = 16)
points(log(x), predict(gala.glm1), col= 2, pch = 16)
points(x, predict(gala.glm1, type="response"), col= 3, pch = 16)
plot(gala.glm1, which = 1)
gala.glm1 = glm(species~1+logarea, data = gala.data, family = poisson(link="sqrt"))
gala.glm1 = glm(species~1+logarea, data = gala.data, family = poisson(link="sqrt"), start = coef(gala.glm1))
warnings()
plot(species~logarea, data = gala.data)
gala.glm1 = glm(species~1+logarea, data = gala.data, family = poisson(link="log"))
gala.glm2 = glm(species~1+logarea, data = gala.data, family = poisson(link="sqrt"), start = coef(gala.glm1))
warnings()
points(x, predict(gala.glm1, type="response"), col= 4, pch = 16)
points(x, predict(gala.glm1, type="response"), col= 3, pch = 16)
points(x, predict(gala.glm1, type="response"), col= 4, pch = 16)
points(x, predict(gala.glm2, type="response"), col= 4, pch = 16)
points(x, predict(gala.glm1, type="response"), col= 3, pch = 16)
lm(sqrt(species)~1+logarea, data = gala.data)
points(x, predict(gala.lm1), col= 5, pch = 16)
gala.lm1 = lm(sqrt(species)~1+logarea, data = gala.data)
points(x, predict(gala.lm1), col= 5, pch = 16)
points(x, (5.453+1.346*x)^2, col= 5, pch = 16)
gala.glm2 = glm(species~1+logarea, data = gala.data, family = poisson(link="sqrt"), start = coef(gala.lm1))
gala.glm4 = glm(species~1+logarea, data = gala.data, family = poisson(link="sqrt"), start = c(0,1))
gala.glm4 = glm(species~1+logarea, data = gala.data, family = poisson(link="sqrt"), start = c(1,0))
warnings()
gala.glm5 = glm(species~1+logarea+scruz, data = gala.data, family = poisson(link="log"))
gala.glm5
miete.data = csv.read("/home/tobias_giesemann/Dropbox/WS1819/01Statistische Verfahren/Daten/mietspiegel.csv",sep = ";")
miete.data = read.csv("/home/tobias_giesemann/Dropbox/WS1819/01Statistische Verfahren/Daten/mietspiegel.csv",sep = ";")
head(miete.data)
miete.data = read.csv("/home/tobias_giesemann/Dropbox/WS1819/01Statistische Verfahren/Daten/mietspiegel.csv",sep = ",")
head(miete.data)
miete.glm1 = glm(miete~1+flaeche, data = miete.data, family = Gamma(link="log"))
plot(miete~flaeche,data = miete.data)
points(miete.data$flaeche, predict(miete.glm1, type = "response"), col = 2, pch=16)
miete.glm1 = glm(miete~1+flaeche, data = miete.data, family = Gamma)
points(miete.data$flaeche, predict(miete.glm1, type = "response"), col = 2, pch=16)
plot(miete~flaeche,data = miete.data)
miete.glm1 = glm(miete~1+flaeche, data = miete.data, family = Gamma)
points(miete.data$flaeche, predict(miete.glm1, type = "response"), col = 2, pch=16)
miete.glm2 = glm(miete~1+flaeche, data = miete.data, family = Gamma(link="identity"))
points(miete.data$flaeche, predict(miete.glm2, type = "response"), col = 3, pch=16)
plot(miete.glm2, which=1)
miete.lm1 = lm(miete~1+flaeche, data = miete.data)
plot(miete~flaeche,data = miete.data)
miete.glm1 = glm(miete~1+flaeche, data = miete.data, family = Gamma)
points(miete.data$flaeche, predict(miete.glm1, type = "response"), col = 2, pch=16)
miete.glm2 = glm(miete~1+flaeche, data = miete.data, family = Gamma(link="identity"))
points(miete.data$flaeche, predict(miete.glm2, type = "response"), col = 3, pch=16)
points(miete.data$flaeche, predict(miete.lm1), col = 4, pch=16)
offen.data = read.csv("/home/tobias_giesemann/Dropbox/WS1819/01Statistische Verfahren/Uebungen/Daten/oedlandschrecke.csv")
head(offen.data)
plot(offen~vorkommen, data = offen.data)
plot(vorkommen~offen, data = offen.data)
offen.int = cut(offen.data$offen, breaks = seq(0,35,7))
offen.int
tapply(offen.data$vorkommen,offen.int,mean)
rel.hfk = tapply(offen.data$vorkommen,offen.int,mean)
points(rel.hfk, pch = 16, col = 2, type = "b")
plot(vorkommen~offen, data = offen.data)
points(seq(3.5, by=7, length.out = 5), rel.hfk, pch = 16, col = 2, type = "b")
offen.glm1 = glm(vorkommen~1+offen, data = offen.data, family=binomial(link = "logit"))
coeff(offen.glm1)
offen.glm1 = glm(vorkommen~1+offen, data = offen.data, family=binomial(link = "logit"))
coeff(offen.glm1)
coef(offen.glm1)
x = seq(0,35,0.1)
points(x,predict(offen.glm1, newdata = data.frame(offen=x), type = "response"), type = "l",col =3)
vcov(offen.glm1)
sqrt(diag(vcov(offen.glm1)))
summary(offen.glm1)
?family
offen.glm2 = glm(vorkommen~1+offen, data = offen.data, family=binomial(link = "probit"))
coef(offen.glm1)
coef(offen.glm2)
x = seq(0,35,0.1)
points(x,predict(offen.glm1, newdata = data.frame(offen=x), type = "response"), type = "l",col =3)
points(x,predict(offen.glm2, newdata = data.frame(offen=x), type = "response"), type = "l",col =3)
points(x,predict(offen.glm2, newdata = data.frame(offen=x), type = "response"), type = "l",col =4)
offen.glm3 = glm(vorkommen~1+offen, data = offen.data, family=binomial(link = "probit"))
coef(offen.glm3)
x = seq(0,35,0.1)
points(x,predict(offen.glm3, newdata = data.frame(offen=x), type = "response"), type = "l",col =5)
offen.glm3 = glm(vorkommen~1+offen, data = offen.data, family=binomial(link = "cloglog"))
coef(offen.glm3)
x = seq(0,35,0.1)
points(x,predict(offen.glm3, newdata = data.frame(offen=x), type = "response"), type = "l",col =5)
points(x,predict(offen.glm3, newdata = data.frame(offen=x), type = "response"), type = "l",col =6)
plot(offen.glm1,which=1)
plot(offen.glm1,which=2)
plot(offen.glm1,which=1)
plot(offen.glm2,which=1)
plot(offen.glm3,which=1)
plot(offen.glm1,which=1)
offen.glm4 = glm(vorkommen~1+offen+I(offen^2), data = offen.data, family=binomial(link = "logit"))
coef(offen.glm1)
points(x,predict(offen.glm4, newdata = data.frame(offen=x), type = "response"), type = "l",col =6)
plot(vorkommen~offen, data = offen.data)
points(seq(3.5, by=7, length.out = 5), rel.hfk, pch = 16, col = 2, type = "b")
points(x,predict(offen.glm1, newdata = data.frame(offen=x), type = "response"), type = "l",col =3)
points(x,predict(offen.glm2, newdata = data.frame(offen=x), type = "response"), type = "l",col =4)
points(x,predict(offen.glm3, newdata = data.frame(offen=x), type = "response"), type = "l",col =6)
offen.glm4 = glm(vorkommen~1+offen+I(offen^2), data = offen.data, family=binomial(link = "logit"))
coef(offen.glm1)
points(x,predict(offen.glm4, newdata = data.frame(offen=x), type = "response"), type = "l",col =6)
points(x,predict(offen.glm4, newdata = data.frame(offen=x), type = "response"), type = "l",col =7)
points(x,predict(offen.glm4, newdata = data.frame(offen=x), type = "response"), type = "l",col =1)
x = seq(0,70,0.1)
points(x,predict(offen.glm4, newdata = data.frame(offen=x), type = "response"), type = "l",col =1)
plot(x,predict(offen.glm4, newdata = data.frame(offen=x), type = "response"), type = "l",col =1)
plot(x,predict(offen.glm1, newdata = data.frame(offen=x), type = "response"), type = "l",col =1)
points(x,predict(offen.glm2, newdata = data.frame(offen=x), type = "response"), type = "l",col =2)
points(x,predict(offen.glm3, newdata = data.frame(offen=x), type = "response"), type = "l",col =3)
points(x,predict(offen.glm4, newdata = data.frame(offen=x), type = "response"), type = "l",col =4)
summary(offen.glm4)
hasel = read.csv("/home/tobias_giesemann/Dropbox/WS1819/01Statistische Verfahren/Uebungen/Daten/hasel.csv")
hasel.data = read.csv("/home/tobias_giesemann/Dropbox/WS1819/01Statistische Verfahren/Uebungen/Daten/hasel.csv")
head(hasel.data)
m0 = gml(besiedel~1, data=hasel.data)
m1 = gml(besiedel~1+lnsize, data=hasel.data)
m2 = gml(besiedel~1+lnsize+gwald, data=hasel.data)
m3 = gml(besiedel~1+lnsize+gwald+lnsize:gwald, data=hasel.data)
m0 = glm(besiedel~1, data=hasel.data)
m1 = glm(besiedel~1+lnsize, data=hasel.data)
m2 = glm(besiedel~1+lnsize+gwald, data=hasel.data)
m3 = glm(besiedel~1+lnsize+gwald+lnsize:gwald, data=hasel.data)
summary(m0)
summary(m1)
summary(m2)
summary(m3)
summary(m2)
hasel.data = read.csv("/home/tobias_giesemann/Dropbox/WS1819/01Statistische Verfahren/Uebungen/Daten/hasel.csv")
head(hasel.data)
m0 = glm(besiedel~1, data=hasel.data)
m1 = glm(besiedel~1+lnsize, data=hasel.data)
m2 = glm(besiedel~1+lnsize+gwald, data=hasel.data)
m3 = glm(besiedel~1+lnsize+gwald+lnsize:gwald, data=hasel.data)
summary(m0)
summary(m1)
summary(m2)
summary(m3)
head(hasel.data)
m0 = glm(besiedel~1, data=hasel.data, family = binomial(link = "logit"))
m1 = glm(besiedel~1+lnsize, data=hasel.data, family = binomial(link = "logit"))
m2 = glm(besiedel~1+lnsize+gwald, data=hasel.data, family = binomial(link = "logit"))
m3 = glm(besiedel~1+lnsize+gwald+lnsize:gwald, data=hasel.data, family = binomial(link = "logit"))
m4 = glm(besiedel~1+umfang+posinsel, data = hasel.data, family = binomial(link = "logit"))
summary(m0)
summary(m1)
summary(m2)
summary(m3)
summary(m4)
AIC_m0 = -2*logLik(m0) + 2*1
# =
AIC(m0)
# =
AIC(m0,m1,m2,m3,m4)
add1(m0,scope = 1+lnsize+umfang+gwald+posinsel+offen)
add1(m0,scope = ~1+lnsize+umfang+gwald+posinsel+offen)
m1 = glm(besiedel~1+offen, data=hasel.data, family = binomial(link = "logit"))
add1(m1,scope = ~1+lnsize+umfang+gwald+posinsel)
add1(m1,scope = ~1+lnsize+umfang+gwald+posinsel+offen)
m2 = glm(besiedel~1+offen+gwald, data=hasel.data, family = binomial(link = "logit"))
add1(m2,scope = ~1+lnsize+umfang+gwald+posinsel+offen)
m3 = glm(besiedel~1+offen+gwald+ lnsize, data=hasel.data, family = binomial(link = "logit"))
add1(m3,scope = ~1+lnsize+umfang+gwald+posinsel+offen)
m4 = glm(besiedel~1+offen+gwald+lnsize,data  = hasel.data,family=binomial(link="logit"))
add1(m4,scope = ~1+lnsize+umfang+gwald+posinsel+offen)
m4 = glm(besiedel~1+offen+gwald+lnsize+posinsel,data  = hasel.data,family=binomial(link="logit"))
add1(m4,scope = ~1+lnsize+umfang+gwald+posinsel+offen)
step(m0, scope = ~1+lnsize+umfang+gwald+posinsel+offen)
step(m0, scope = ~(1+lnsize+umfang+gwald+posinsel+offen)^2)
hasel.data = read.csv("/home/tobias_giesemann/Dropbox/WS1819/01Statistische Verfahren/Uebungen/Daten/seeds.csv")
seeds.data = read.csv("/home/tobias_giesemann/Dropbox/WS1819/01Statistische Verfahren/Uebungen/Daten/seeds.csv")
head(seeds.data)
seeds.data
m1  = glm(seeds~1+treatment, data = seeds.data,family = posson(link="identity"))
m0  = glm(seeds~1, data = seeds.data,family = poisson(link="identity"))
m1  = glm(seeds~1+treatment, data = seeds.data,family = poisson(link="identity"))
m1
seeds.data$treatment = relevel(seeds.data$treatment, ref="control")
m0  = glm(seeds~1, data = seeds.data,family = poisson(link="identity"))
m1  = glm(seeds~1+treatment, data = seeds.data,family = poisson(link="identity"))
m1
summary(m1)
m2  = glm(seeds~1+treatment+stress, data = seeds.data,family = poisson(link="identity"))
m3  = glm(seeds~1+treatment+stress+treatment:stress, data = seeds.data,family = poisson(link="identity"))
T.stat = 2*(logLik(m1)-logLik(m0))
T.stat
1-pchisq(T.stat, df = 2)
anova(m0,m1)
anova(m0,m1, test = "LRT")
anova(m0,m1,m2,m3, test = "LRT")
plot(seeds~interaction(treatment,stress),data = seeds.data)
plot(seeds~interaction(stress,treatment),data = seeds.data)
seeds.data = read.csv("/home/tobias_giesemann/Dropbox/WS1819/01Statistische Verfahren/Uebungen/Daten/schule.csv")
schule.data= read.csv("/home/tobias_giesemann/Dropbox/WS1819/01Statistische Verfahren/Uebungen/Daten/schule.csv")
head(schule)
head(schule.data)
anova(m0,m1,m2,m3, test = "LRT")
m0 = glm(daysabs~1, data=schule.data,family=poisson)
m1 = glm(daysabs~1+male, data=schule.data,family=poisson)
m2 = glm(daysabs~1+male+math, data=schule.data,family=poisson)
m3 = glm(daysabs~1+male+math+male:math, data=schule.data,family=poisson)
anova(m0,m1,m2,m3, test = "LRT")
plot(daysabs~math, data = schule.data, col = male+1,pch=16)
# modelle hoch signifikant, aber Daten sehen nicht nach so einem starken zusammenhang aus...
# Poisson Verteilung falsch, erstelle passende Daten als Bsp:
pseudo.data = rpois(316, lambda = predict(m3,type = "response"))
points(schule.data$math, pseudo.data, col = schule.data$male+3, pch=16)
require(MASS)
m0 = glm.nb(daysabs~1, data=schule.data)
m1 = glm.nb(daysabs~1+male, data=schule.data)
m2 = glm.nb(daysabs~1+male+math, data=schule.data)
m3 = glm.nb(daysabs~1+male+math+male:math, data=schule.data
summary(m3)
summary(m3)
m0 = glm.nb(daysabs~1, data=schule.data)
m1 = glm.nb(daysabs~1+male, data=schule.data)
m2 = glm.nb(daysabs~1+male+math, data=schule.data)
m3 = glm.nb(daysabs~1+male+math+male:math, data=schule.data)
summary(m3)
plot(daysabs~math, data = schule.data, col = male+1,pch=16)
pseudo.data.nb = rnegbin(316,mu = predict(m3,type = "response"), theta = 0.7675)
points(schule.data$math, pseudo.data, col = schule.data$male+3,pch=16)
pseudo.data.nb = rnegbin(316,mu = predict(m3,type = "response"), theta = 0.7675)
plot(daysabs~math, data = schule.data, col = male+1,pch=16)
pseudo.data.nb = rnegbin(316,mu = predict(m3,type = "response"), theta = 0.7675)
points(schule.data$math, pseudo.data, col = schule.data$male+3,pch=16)
plot(daysabs~math, data = schule.data, col = male+1,pch=16)
points(schule.data$math, pseudo.data.nb, col = schule.data$male+3,pch=16)
schule.data= read.csv("/home/tobias_giesemann/Dropbox/WS1819/01Statistische Verfahren/Uebungen/Daten/schule.csv")
head(schule.data)
m0 = glm(daysabs~1, data=schule.data,family=poisson)
m1 = glm(daysabs~1+male, data=schule.data,family=poisson)
m2 = glm(daysabs~1+male+math, data=schule.data,family=poisson)
m3 = glm(daysabs~1+male+math+male:math, data=schule.data,family=poisson)
anova(m0,m1,m2,m3, test = "LRT")
plot(daysabs~math, data = schule.data, col = male+1,pch=16)
# modelle hoch signifikant, aber Daten sehen nicht nach so einem starken zusammenhang aus...
# Poisson Verteilung falsch, erstelle passende Daten als Bsp:
pseudo.data = rpois(316, lambda = predict(m3,type = "response"))
points(schule.data$math, pseudo.data, col = schule.data$male+3, pch=16)
require(MASS)
m0 = glm.nb(daysabs~1, data=schule.data)
m1 = glm.nb(daysabs~1+male, data=schule.data)
m2 = glm.nb(daysabs~1+male+math, data=schule.data)
m3 = glm.nb(daysabs~1+male+math+male:math, data=schule.data)
summary(m3)
plot(daysabs~math, data = schule.data, col = male+1,pch=16)
pseudo.data.nb = rnegbin(316,mu = predict(m3,type = "response"), theta = 0.7675)
points(schule.data$math, pseudo.data.nb, col = schule.data$male+3,pch=16)
plot(daysabs~math, data = schule.data, col = male+1,pch=16)
pseudo.data.nb = rnegbin(316,mu = predict(m3,type = "response"), theta = 0.7675)
points(schule.data$math, pseudo.data.nb, col = schule.data$male+3,pch=16)
anova(m0,m1,m2,m3, test = "LRT")
plot(daysabs~math, data = schule.data, col = male+1,pch=16)
# modelle hoch signifikant, aber Daten sehen nicht nach so einem starken zusammenhang aus...
# Poisson Verteilung falsch, erstelle passende Daten als Bsp:
pseudo.data = rpois(316, lambda = predict(m3,type = "response"))
points(schule.data$math, pseudo.data, col = schule.data$male+3, pch=16)
require(MASS)
m0 = glm.nb(daysabs~1, data=schule.data)
m1 = glm.nb(daysabs~1+male, data=schule.data)
m2 = glm.nb(daysabs~1+male+math, data=schule.data)
m3 = glm.nb(daysabs~1+male+math+male:math, data=schule.data)
summary(m3)
plot(daysabs~math, data = schule.data, col = male+1,pch=16)
pseudo.data.nb = rnegbin(316,mu = predict(m3,type = "response"), theta = 0.7675)
points(schule.data$math, pseudo.data.nb, col = schule.data$male+3,pch=16)
m3 = glm(daysabs~1+male+math+male:math, data=schule.data,family=poisson)
summary(m3)
m3 = glm.nb(daysabs~1+male+math+male:math, data=schule.data)
summary(m3)
miete.data= read.csv("/home/tobias_giesemann/Dropbox/WS1819/01Statistische Verfahren/Uebungen/Daten/miete.csv")
miete.data= read.csv("/home/tobias_giesemann/Dropbox/WS1819/01Statistische Verfahren/Uebungen/Daten/miete.csv")
head(miete)
head(miete.data)
miete.lm1 = lm(miete~1+flaeche, data= miete.data)
miete.glm1 = glm(miete~1+flaeche, family=Gamma(link="identity"), data = miete.data)
summary(miete.lm1)
summary(miete.glm1)
summary(miete.lm1)
summary(miete.glm1)
AIC(miete.lm1, miete.glm1)
miete.data= read.csv("/home/tobias_giesemann/Dropbox/WS1819/01Statistische Verfahren/Uebungen/Daten/stembiomas.csv")
miete.data= read.csv("/home/tobias_giesemann/Dropbox/WS1819/01Statistische Verfahren/Uebungen/Daten/stembiomass.csv")
stem.data= read.csv("/home/tobias_giesemann/Dropbox/WS1819/01Statistische Verfahren/Uebungen/Daten/stembiomass.csv")
head(stem.data)
stem.data= read.csv("/home/tobias_giesemann/Dropbox/WS1819/01Statistische Verfahren/Uebungen/Daten/stembiomass.csv", sep= ";")
head(stem.data)
plot(stem~d, data = stem.data)
stem.lm = lm(log(stem)~log(d), data = stem.data)
plot(log(stem)~log(d), data = stem.data)
stem.lm = lm(log(stem)~log(d), data = stem.data)
summary(stem.lm)
nir.data = csv.read("/home/tobias_giesemann/Dropbox/Uni_Master/01WS1819/01Statistische Verfahren/Projekt/2018_WS_7_2_3_Projekt 4.1/NIR.csv")
nir.data = read.csv("/home/tobias_giesemann/Dropbox/Uni_Master/01WS1819/01Statistische Verfahren/Projekt/2018_WS_7_2_3_Projekt 4.1/NIR.csv")
plot(nir.data$N, nir.data$nm1408)
plot(nir.data$N, nir.data$nm1408, xlim=(-100,100),ylim=(-100,100))
cities.data = read.csv("C:/Users/wa78sej/Desktop/cities.csv")
head(cities.data)
plot(y~x6, data=cities.data)
### Zerlegung in Trainings- und Testdaten
index = sample(1:41, 10)
cities.test = cities.data[index,]
cities.train = cities.data[-index,]
lm1 = lm(y~1+x3,data=cities.train)
lm2 = lm(y~1+x5,data=cities.train)
lm3 = lm(y~1+x5+x6,data=cities.train)
lm4 = lm(y~1+x6,data=cities.train)
lm5 = lm(y~1+x3+x6,data=cities.train)
lm6 = lm(y~1+x1+x2+x3+x4+x5+x6,data=cities.train)
lm7 = lm(y~1+x3+x6+x3:x6,data=cities.train)
### Sch?tzung des erwarteten Prognosefehler
sum((cities.test$y-predict(lm1,newdata=cities.test))^2)
sum((cities.test$y-predict(lm2,newdata=cities.test))^2)
sum((cities.test$y-predict(lm3,newdata=cities.test))^2)
sum((cities.test$y-predict(lm4,newdata=cities.test))^2)
sum((cities.test$y-predict(lm5,newdata=cities.test))^2)
sum((cities.test$y-predict(lm6,newdata=cities.test))^2)
sum((cities.test$y-predict(lm7,newdata=cities.test))^2)
### Kreuzvalidierung
index = rep(1:7,length.out=41)
index = sample(index)
spse1 = spse2 = spse3 = spse4 = spse5 = spse6 = spse7 = 0
for(i in 1:7){
###Zerlegung
cities.test = cities.data[index==i,]
cities.train = cities.data[index!=i,]
### Parametersch?tzung
lm1 = lm(y~1+x3,data=cities.train)
lm2 = lm(y~1+x5,data=cities.train)
lm3 = lm(y~1+x5+x6,data=cities.train)
lm4 = lm(y~1+x6,data=cities.train)
lm5 = lm(y~1+x3+x6,data=cities.train)
lm6 = lm(y~1+x1+x2+x3+x4+x5+x6,data=cities.train)
lm7 = lm(y~1+x3+x6+x3:x6,data=cities.train)
### Sch?tzung des erwarteten Prognosefehlers
spse1 = spse1 + sum((cities.test$y-predict(lm1,newdata=cities.test))^2)
spse2 = spse2 + sum((cities.test$y-predict(lm2,newdata=cities.test))^2)
spse3 = spse3 + sum((cities.test$y-predict(lm3,newdata=cities.test))^2)
spse4 = spse4 + sum((cities.test$y-predict(lm4,newdata=cities.test))^2)
spse5 = spse5 + sum((cities.test$y-predict(lm5,newdata=cities.test))^2)
spse6 = spse6 + sum((cities.test$y-predict(lm6,newdata=cities.test))^2)
spse7 = spse7 + sum((cities.test$y-predict(lm7,newdata=cities.test))^2)
}
spse1
spse2
spse3
spse4
spse5
spse6
spse7
###basierend auf RSS
### Parametersch?tzung
lm1 = lm(y~1+x3,data=cities.data)
lm2 = lm(y~1+x5,data=cities.data)
lm3 = lm(y~1+x5+x6,data=cities.data)
lm4 = lm(y~1+x6,data=cities.data)
lm5 = lm(y~1+x3+x6,data=cities.data)
lm6 = lm(y~1+x1+x2+x3+x4+x5+x6,data=cities.data)
lm7 = lm(y~1+x3+x6+x3:x6,data=cities.data)
###
rss1 = sum(residuals(lm1)^2)
rss2 = sum(residuals(lm2)^2)
rss3 = sum(residuals(lm3)^2)
rss4 = sum(residuals(lm4)^2)
rss5 = sum(residuals(lm5)^2)
rss6 = sum(residuals(lm6)^2)
rss7 = sum(residuals(lm7)^2)
### maximales Modell
lm8 = lm(y~1+x1+x2+x3+x4+x5+x6+x3:x6,data=cities.data)
rss8 = sum(residuals(lm8)^2)
sigma2.tilde.full = rss8/(41-8)
spse1 = spse1 + rss1+2*sigma2.tilde.full*(1+1)
spse2 = spse2 + rss2+2*sigma2.tilde.full*(1+1)
spse3 = spse3 + rss3+2*sigma2.tilde.full*(2+1)
spse4 = spse4 + rss4+2*sigma2.tilde.full*(1+1)
spse5 = spse5 + rss5+2*sigma2.tilde.full*(2+1)
spse6 = spse6 + rss6+2*sigma2.tilde.full*(6+1)
spse7 = spse7 + rss7+2*sigma2.tilde.full*(3+1)
### Mallow's Cp:
require(leaps)
cities.bss = regsubsets(y~1+x1+x2+x3+x4+x5+x6+x3:x6,data=cities.data)
# Falls x viele Variablen, nimm angezeigte variablen
summary(cities.bss)
# Bestes Modell hat kleinsten Wert
summary(cities.bss)$cp
cities.bss = regsubsets(y~1+x1+x2+x3+x4+x5+x6+x3:x6,data=cities.data, nbest = 3)
# Falls x viele Variablen, nimm angezeigte variablen
summary(cities.bss)
# Bestes Modell hat kleinsten Wert
summary(cities.bss)$cp
cbind(summary(cities.bss)$cp,summary(cities.bss)$which)
##Sch?tzung von SPSE:
summary(cities.bss)$cp*sigma2.tilde.full+41*sigma2.tilde.full
spse6
getDiff = function(row, n) {
x=c()
for (i in 1:317) {
x[i] = abs(row[i]-row[i+1])
}
return(x)
}
getDiffMatrix = function(M, rows, cols) {
x1 = getDiff(t(M)[,1], cols)
x2 = getDiff(t(M)[,2], cols)
x=rbind(x1,x2)
for (i in 3:rows) {
x = rbind(x, getDiff(t(M)[,i], cols))
}
return(x)
}
nirs.data = read.csv("NIR.csv", sep=";")
head(nirs.data)
# nir data only
nir.data = nirs.data[, 4:322]
# wavelengths
x=seq(1400, 2664, 4)
plot(5,3)
plot(seq(1400, 2672, 4), nir.data[1,], type='l', col=1, ylim=c(0.1,0.7))
lines(seq(1400, 2672, 4), nir.data[2,], type='l', col=2, ylim=c(0.3,0.7))
lines(seq(1400, 2672, 4), nir.data[3,], type='l', col=3, ylim=c(0.3,0.7))
lines(seq(1400, 2672, 4), nir.data[4,], type='l', col=4, ylim=c(0.3,0.7))
lines(seq(1400, 2672, 4), nir.data[5,], type='l', col=5, ylim=c(0.3,0.7))
# p
getDiffMatrix = function(M, rows, cols) {
x1 = getDiff(t(M)[,1], cols)
x2 = getDiff(t(M)[,2], cols)
x=rbind(x1,x2)
for (i in 3:rows) {
x = rbind(x, getDiff(t(M)[,i], cols))
}
return(x)
}
nirs.data = read.csv("NIR.csv", sep=";")
setwd("~/Dropbox/Uni_Master/01WS1819/01Statistische Verfahren/Projekt/project_git/NIR-WS1819")
nirs.data = read.csv("NIR.csv", sep=";")
head(nirs.data)
# nir data only
nir.data = nirs.data[, 4:322]
# wavelengths
x=seq(1400, 2664, 4)
plot(5,3)
plot(seq(1400, 2672, 4), nir.data[1,], type='l', col=1, ylim=c(0.1,0.7))
lines(seq(1400, 2672, 4), nir.data[2,], type='l', col=2, ylim=c(0.3,0.7))
lines(seq(1400, 2672, 4), nir.data[3,], type='l', col=3, ylim=c(0.3,0.7))
lines(seq(1400, 2672, 4), nir.data[4,], type='l', col=4, ylim=c(0.3,0.7))
lines(seq(1400, 2672, 4), nir.data[5,], type='l', col=5, ylim=c(0.3,0.7))
# plot first deviation for first 6 records
plot(x, getDiff(t(nir.data)[,1], 318), type='l', col=1)
lines(x, getDiff(t(nir.data)[,2], 318), type='l', col=2)
lines(x, getDiff(t(nir.data)[,3], 318), type='l', col=3)
lines(x, getDiff(t(nir.data)[,4], 318), type='l', col=4)
lines(x, getDiff(t(nir.data)[,5], 318), type='l', col=5)
lines(x, getDiff(t(nir.data)[,6], 318), type='l', col=6)
# calculate first deviation for the whole dataset
M = getDiffMatrix(nir.data, 533, 318)
# first deviation average
Mavg = colMeans(M)
plot(x, Mavg, type='l', col=1)
# threshold
THRESHOLD = 0.0015
abline(h=THRESHOLD, col=2)
# plot first deviation for first 6 records
plot(x, getDiff(t(nir.data)[,1], 318), type='l', col=1)
lines(x, getDiff(t(nir.data)[,2], 318), type='l', col=2)
lines(x, getDiff(t(nir.data)[,3], 318), type='l', col=3)
lines(x, getDiff(t(nir.data)[,4], 318), type='l', col=4)
lines(x, getDiff(t(nir.data)[,5], 318), type='l', col=5)
lines(x, getDiff(t(nir.data)[,6], 318), type='l', col=6)
abline(h=THRESHOLD, col=2)
