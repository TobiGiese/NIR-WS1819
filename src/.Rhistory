p1 <- (pnorm((5+sqrt(2)),mean=5,sd=sqrt(2)) - pnorm(sqrt(2),mean=5,sd=sqrt(2)))
p2 <- (pnorm(2*(5+sqrt(2)),mean=5,sd=sqrt(2)) - pnorm(2*sqrt(2),mean=5,sd=sqrt(2)))
p3 <- (pnorm(3*(5+sqrt(2)),mean=5,sd=sqrt(2)) - pnorm(3*sqrt(2),mean=5,sd=sqrt(2)))
p1 <- (pnorm((5+sqrt(2)),mean=5,sd=sqrt(2)) - pnorm(sqrt(2),mean=5,sd=sqrt(2)))
p2 <- (pnorm(2*(5+sqrt(2)),mean=5,sd=sqrt(2)) - pnorm(2*sqrt(2),mean=5,sd=sqrt(2)))
p3 <- (pnorm(3*(5+sqrt(2)),mean=5,sd=sqrt(2)) - pnorm(3*sqrt(2),mean=5,sd=sqrt(2)))
### Vergleich mit theoretischer Verteilungsfunktion
plot(ecdf(y))
points(z, pnorm(z), type="l", col=3)
p1 <- (pnorm((5+sqrt(2)),mean=5,sd=sqrt(2)) - pnorm(sqrt(2),mean=5,sd=sqrt(2)))
p2 <- (pnorm((5+2*sqrt(2)),mean=5,sd=sqrt(2)) - pnorm(2*sqrt(2),mean=5,sd=sqrt(2)))
p3 <- (pnorm((5+3*sqrt(2)),mean=5,sd=sqrt(2)) - pnorm(3*sqrt(2),mean=5,sd=sqrt(2)))
p3 <- (pnorm((5+(3*sqrt(2))),mean=5,sd=sqrt(2)) - pnorm(3*sqrt(2),mean=5,sd=sqrt(2)))
p2 <- (pnorm((5+2*sqrt(2)),mean=5,sd=sqrt(2)) - pnorm(2*sqrt(2),mean=5,sd=sqrt(2)))
p3 <- (pnorm((5+(3*sqrt(2))),mean=5,sd=sqrt(2)) - pnorm(3*sqrt(2),mean=5,sd=sqrt(2)))
p1 <- (pnorm((5+sqrt(2)),mean=5,sd=sqrt(2)) - pnorm(5-sqrt(2),mean=5,sd=sqrt(2)))
p2 <- (pnorm(5+2*sqrt(2)),mean=5,sd=sqrt(2)) - pnorm(5-2*sqrt(2),mean=5,sd=sqrt(2))
p3 <- (pnorm(5+3*sqrt(2)),mean=5,sd=sqrt(2)) - pnorm(5-3*sqrt(2),mean=5,sd=sqrt(2))
p1 <- (pnorm((5+sqrt(2)), mean=5,sd=sqrt(2)) - pnorm(5-sqrt(2),mean=5,sd=sqrt(2)))
p1 <- (pnorm((5+sqrt(2)),mean=5,sd=sqrt(2)) - pnorm(5-sqrt(2),mean=5,sd=sqrt(2)))
p2 <- (pnorm((5+2*sqrt(2)),mean=5,sd=sqrt(2)) - pnorm(5-2*sqrt(2),mean=5,sd=sqrt(2)))
p3 <- (pnorm((5+3*sqrt(2)),mean=5,sd=sqrt(2)) - pnorm(5-3*sqrt(2),mean=5,sd=sqrt(2)))
p1 <- (pnorm((o+s),mean=o,sd=s - pnorm(o-s),mean=o,sd=s))
# mehrfache Simulation -> Vektor von Pseudozufallszahlen/Pseudobeobachtungen
y <- runif(10000)
y
plot(y)
# mehrfache Simulation -> Vektor von Pseudozufallszahlen/Pseudobeobachtungen
y <- runif(10000)
plot(y)
# mehrfache Simulation -> Vektor von Pseudozufallszahlen/Pseudobeobachtungen
y <- runif(3)
plot(y)
# mehrfache Simulation -> Vektor von Pseudozufallszahlen/Pseudobeobachtungen
y <- runif(3)
plot(y)
# mehrfache Simulation -> Vektor von Pseudozufallszahlen/Pseudobeobachtungen
y <- runif(3)
plot(y)
# mehrfache Simulation -> Vektor von Pseudozufallszahlen/Pseudobeobachtungen
y <- runif(3)
plot(y)
# mehrfache Simulation -> Vektor von Pseudozufallszahlen/Pseudobeobachtungen
y <- runif(3)
plot(y)
# mehrfache Simulation -> Vektor von Pseudozufallszahlen/Pseudobeobachtungen
y <- 1/3*(runif(1)+runif(1)+runif(1))
y
# mehrfache Simulation -> Vektor von Pseudozufallszahlen/Pseudobeobachtungen
y <- 1/3*(runif(1)+runif(1)+runif(1))
y
plot(y)
# mehrfache Simulation -> Vektor von Pseudozufallszahlen/Pseudobeobachtungen
y <- 1/3*(runif(1000)+runif(1000)+runif(1000))
y
plot(y)
# mehrfache Simulation -> Vektor von Pseudozufallszahlen/Pseudobeobachtungen
y <- 1/3*(runif(1000)+runif(1000)+runif(1000))
y
# mehrfache Simulation -> Vektor von Pseudozufallszahlen/Pseudobeobachtungen
y <- 1/3*(runif(1000)+runif(1000)+runif(1000))
y
plot(y)
# mehrfache Simulation -> Vektor von Pseudozufallszahlen/Pseudobeobachtungen
y <- 1/3*(runif(1000)+runif(1000)+runif(1000))
y
plot(y)
# mehrfache Simulation -> Vektor von Pseudozufallszahlen/Pseudobeobachtungen
y <- 1/3*(runif(1000)+runif(1000)+runif(1000))
y
plot(y)
# Vergleich mit Kenngr??en der Verteilung
mean(y)       # theoretischer Erwartungswert: E Y = 0.5
var(y)*12     # theoretische Varianz:      Var(Y) = 1/12
### Vergleich mit theoretischer Dichtefunktion
grenzen <- seq(0,1,length.out=11)
### absolute H?ufigkeiten in Teilintervallen
hist(y, breaks=grenzen)
# mehrfache Simulation -> Vektor von Pseudozufallszahlen/Pseudobeobachtungen
x <- runif(1000)
plot(x)
y <- 1/3*(runif(1000)+runif(1000)+runif(1000))
y
plot(y)
# mehrfache Simulation -> Vektor von Pseudozufallszahlen/Pseudobeobachtungen
x <- runif(1000)
plot(x)
y <- 1/3*(runif(1000)+runif(1000)+runif(1000))
y
plot(y)
y2 <- 1/10*(runif(1000)+runif(1000)+runif(1000)+runif(1000)+runif(1000)+runif(1000)+runif(1000)+runif(1000)+runif(1000)+runif(1000))
plot(y2)
s <- 1/(1-0.6 + (0.6/n))
plot(s~n)
n <- seq(1:100, 1)
n <- seq(1,100, 1)
s <- 1/(1-0.6 + (0.6/n))
plot(s~n)
n <- seq(1,100000, 1)
s <- 1/(1-0.6 + (0.6/n))
plot(s~n)
n <- seq(1,1000, 1)
s <- 1/(1-0.6 + (0.6/n))
plot(s~n)
?model.matrix
design_mat <- model.matrix(mod.nir)
setwd("~/Dropbox/Studium/Stat. Verfahren/Projekt")
nirs.data <- read.csv("NIR.csv", sep = ";")
# Die Wellenlänge sind eindeutig mit einander korreliert --> Model kann reduziert werden
# Auswahl jeder 5ten Wellenlänge
x = seq(4,322, 5)
nir.data <- nirs.data[,c(2,x)]
require(leaps)
subsets=regsubsets(N~1+nm1480+nm1500+nm1520+nm1540+nm1560+nm1580+nm1600+nm1620+nm1640+nm1960+
nm1980+nm2000+nm2020+nm2100+nm2120+nm2140+nm2160+nm2180+nm2200+nm2220+
nm2240+nm2260+nm2280+nm2380+nm2400+nm2420+nm2440+nm2460+nm2480+nm2500+
nm2520+nm2540+nm2560+nm2580+nm2600+nm2620+nm2640+nm2660, nir.data, really.big=T, nvmax=39)
summary(subsets)$cp
# Save best model
i <- 24 # Index of model in summary
X <- summary(subsets)$which
xvars <- dimnames(X)[[2]][-1]
responsevar <- "N"
id <- X[i,]
form <- reformulate(xvars[which(id[-1])], responsevar, id[1])
mod.nir <- lm(form, nir.data)
design_mat <- model.matrix(mod.nir)
design_mat
pseudo_mat <- as.matrix(read.csv(pseudo.csv, header = F, sep="\t"))
pseudo_mat <- as.matrix(read.csv("pseudo.csv", header = F, sep="\t"))
id
id[-1]
id[1]
class(id)
class(id[1])
xvars[which(id[-1])]
nir_names_vec <- (nirs.data[1,])
View(nir_names_vec)
nir_names_vec <- colnames(nirs.data)
# Die Wellenlänge sind eindeutig mit einander korreliert --> Model kann reduziert werden
# Auswahl jeder 5ten Wellenlänge
dim_nirs_wl <- dim(nirs.data)[2] -3
nir_names_vec <- colnames(nirs.data[,4:dim_nirs_wl])
#Ermittle Index der ausgewählten Wellenlängen in Datensatz
nir_names_vec <- as.vector(colnames(nirs.data[,4:dim_nirs_wl]))
xvars[which(id[-1])]
ixd_vec <- match(nir_names_vec, xvars[which(id[-1])])
ixd_vec <- which(name %in% nir_names_vec)
name <- xvars[which(id[-1])]
ixd_vec <- which(name %in% nir_names_vec)
name <- as.vector(xvars[which(id[-1])])
ixd_vec <- which(name %in% nir_names_vec)
ixd_vec <- match(nir_names_vec, xvars[which(id[-1])])
getDiff = function(row, n) {
x=c()
for (i in 1:317) {
x[i] = abs(row[i]-row[i+1])
}
return(x)
}
getDiffMatrix = function(M, rows, cols) {
x1 = getDiff(t(M)[,1], cols)
x2 = getDiff(t(M)[,2], cols)
x=rbind(x1,x2)
for (i in 3:rows) {
x = rbind(x, getDiff(t(M)[,i], cols))
}
return(x)
}
nirs.data = read.csv("../NIR.csv", sep=";")
getDiff = function(row, n) {
x=c()
for (i in 1:317) {
x[i] = abs(row[i]-row[i+1])
}
return(x)
}
getDiffMatrix = function(M, rows, cols) {
x1 = getDiff(t(M)[,1], cols)
x2 = getDiff(t(M)[,2], cols)
x=rbind(x1,x2)
for (i in 3:rows) {
x = rbind(x, getDiff(t(M)[,i], cols))
}
return(x)
}
nirs.data = read.csv("../NIR.csv", sep=";")
setwd("~/Dropbox/Studium/Stat. Verfahren/NIR-WS1819/src")
nirs.data = read.csv("../NIR.csv", sep=";")
head(nirs.data)
# nir data only
nir.data = nirs.data[, 4:322]
# wavelengths
x=seq(1400, 2664, 4)
plot(seq(1400, 2672, 4), nir.data[1,], type='l', col=1, ylim=c(0.3,0.7))
lines(seq(1400, 2672, 4), nir.data[2,], type='l', col=2, ylim=c(0.3,0.7))
lines(seq(1400, 2672, 4), nir.data[3,], type='l', col=3, ylim=c(0.3,0.7))
lines(seq(1400, 2672, 4), nir.data[4,], type='l', col=4, ylim=c(0.3,0.7))
lines(seq(1400, 2672, 4), nir.data[5,], type='l', col=5, ylim=c(0.3,0.7))
# plot first deviation for first 6 records
plot(x, getDiff(t(nir.data)[,1], 318), type='l', col=1)
lines(x, getDiff(t(nir.data)[,2], 318), type='l', col=2)
lines(x, getDiff(t(nir.data)[,3], 318), type='l', col=3)
lines(x, getDiff(t(nir.data)[,4], 318), type='l', col=4)
lines(x, getDiff(t(nir.data)[,5], 318), type='l', col=5)
lines(x, getDiff(t(nir.data)[,6], 318), type='l', col=6)
# calculate first deviation for the whole dataset
M = getDiffMatrix(nir.data, 533, 318)
# first deviation average
Mavg = colMeans(M)
plot(x, Mavg, type='l', col=1)
# threshold
THRESHOLD = 0.0015
abline(h=THRESHOLD, col=2)
# filter dataset for colunms having an average value (1. deviation) above threshold
df = data.frame(x, colnames(nirs.data[, 4:320]), Mavg)
colnames(df) = c("x", "nm", "y")
filteredAvg1stDev = subset(df, y >= THRESHOLD, select=c("x", "nm", "y"));
nrow(filteredAvg1stDev)
plot(filteredAvg1stDev$x, filteredAvg1stDev$y, type='p', col=1)
nirs_filtered.data = subset(nirs.data, select=c(c("SOC", "N", "pH"), as.character(filteredAvg1stDev[,"nm"])))
### Mallows CP
require(leaps)
# Select model
subsets = regsubsets( N ~ nm2144+nm2148+nm2152+nm2156+nm2160+nm2164+nm2168+nm2172+nm2176+nm2180+nm2216+nm2220+nm2408+nm2412+nm2416+nm2424+nm2428+nm2476+nm2480+nm2504+nm2508+nm2512+nm2552+nm2556+nm2560+nm2564+nm2568+nm2572+nm2576+nm2580+nm2584+nm2588+nm2592+nm2596+nm2600+nm2656+nm2660+nm2664, nirs_filtered.data, really.big=F, nvmax=38)
optModelId = which.min(summary(subsets)$cp)
coeffs = coef(subsets, optModelId)
# ##########################################################
# ## SIMULATION
# ##########################################################
getColumnMean = function(colname, data) {
return(mean(data[,colname]))
}
getColumnSD = function(colname, data) {
return(sd(data[,colname]))
}
simulateColumn = function(num, colname, data.origin, TIMES) {
data = data.frame(matrix(nrow=num, ncol=TIMES));
for (i in 1:TIMES) {
data[i] = rnorm(num, mean=getColumnMean(colname, data.origin), sd = getColumnSD(colname, data.origin))
}
dataAVG = rowMeans(data)
return(dataAVG)
}
simulateDataset = function(numRows, coeffs, data.origin, TIMES) {
sim.data = data.frame(matrix(nrow=numRows));
# simulate nir data
for (feature in colnames(data.origin)[-1:-3]) {
sim.data[,feature] = simulateColumn(numRows, feature, data.origin, TIMES)
}
# use estimated coefficients to calculate value for N
sim.data$N = as.vector(coeffs)[1];
for (feature in names(coeffs[-1])) {
sim.data$N = sim.data$N + coeffs[feature] + sim.data[,feature]
}
return(sim.data[,-1])
}
set.seed(13)
simdata = simulateDataset(30, coeffs, nirs.data, 100);
simdata
data = data.frame(matrix(nrow=num, ncol=TIMES));
design_mat <- model.matrix(subsets, optModelId)
X <- summary(subsets)$which
xvars <- dimnames(X)[[2]][-1]
responsevar <- "N"
id <- X[optModelId,]
name <- as.vector(xvars[which(id[-1])])
form <- reformulate(xvars[which(id[-1])], responsevar, id[1])
mod.nir <- lm(form, nir.data)
View(mod.nir)
getDiff = function(row, n) {
x=c()
for (i in 1:317) {
x[i] = abs(row[i]-row[i+1])
}
return(x)
}
getDiffMatrix = function(M, rows, cols) {
x1 = getDiff(t(M)[,1], cols)
x2 = getDiff(t(M)[,2], cols)
x=rbind(x1,x2)
for (i in 3:rows) {
x = rbind(x, getDiff(t(M)[,i], cols))
}
return(x)
}
nirs.data = read.csv("../NIR.csv", sep=";")
head(nirs.data)
# nir data only
nir.data = nirs.data[, 4:322]
# wavelengths
x=seq(1400, 2664, 4)
plot(seq(1400, 2672, 4), nir.data[1,], type='l', col=1, ylim=c(0.3,0.7))
lines(seq(1400, 2672, 4), nir.data[2,], type='l', col=2, ylim=c(0.3,0.7))
lines(seq(1400, 2672, 4), nir.data[3,], type='l', col=3, ylim=c(0.3,0.7))
lines(seq(1400, 2672, 4), nir.data[4,], type='l', col=4, ylim=c(0.3,0.7))
lines(seq(1400, 2672, 4), nir.data[5,], type='l', col=5, ylim=c(0.3,0.7))
# plot first deviation for first 6 records
plot(x, getDiff(t(nir.data)[,1], 318), type='l', col=1)
lines(x, getDiff(t(nir.data)[,2], 318), type='l', col=2)
lines(x, getDiff(t(nir.data)[,3], 318), type='l', col=3)
lines(x, getDiff(t(nir.data)[,4], 318), type='l', col=4)
lines(x, getDiff(t(nir.data)[,5], 318), type='l', col=5)
lines(x, getDiff(t(nir.data)[,6], 318), type='l', col=6)
# calculate first deviation for the whole dataset
M = getDiffMatrix(nir.data, 533, 318)
# first deviation average
Mavg = colMeans(M)
plot(x, Mavg, type='l', col=1)
# threshold
THRESHOLD = 0.0015
abline(h=THRESHOLD, col=2)
# filter dataset for colunms having an average value (1. deviation) above threshold
df = data.frame(x, colnames(nirs.data[, 4:320]), Mavg)
colnames(df) = c("x", "nm", "y")
filteredAvg1stDev = subset(df, y >= THRESHOLD, select=c("x", "nm", "y"));
nrow(filteredAvg1stDev)
plot(filteredAvg1stDev$x, filteredAvg1stDev$y, type='p', col=1)
nirs_filtered.data = subset(nirs.data, select=c(c("SOC", "N", "pH"), as.character(filteredAvg1stDev[,"nm"])))
### Mallows CP
require(leaps)
# Select model
subsets = regsubsets( N ~ nm2144+nm2148+nm2152+nm2156+nm2160+nm2164+nm2168+nm2172+nm2176+nm2180+nm2216+nm2220+nm2408+nm2412+nm2416+nm2424+nm2428+nm2476+nm2480+nm2504+nm2508+nm2512+nm2552+nm2556+nm2560+nm2564+nm2568+nm2572+nm2576+nm2580+nm2584+nm2588+nm2592+nm2596+nm2600+nm2656+nm2660+nm2664, nirs_filtered.data, really.big=F, nvmax=38)
optModelId = which.min(summary(subsets)$cp)
coeffs = coef(subsets, optModelId)
X <- summary(subsets)$which
xvars <- dimnames(X)[[2]][-1]
responsevar <- "N"
id <- X[optModelId,]
name <- as.vector(xvars[which(id[-1])])
form <- reformulate(xvars[which(id[-1])], responsevar, id[1])
mod.nir <- lm(form, nir.data)
optModelId
id
# Select model
subsets = regsubsets( N ~ 1+nm2144+nm2148+nm2152+nm2156+nm2160+nm2164+nm2168+nm2172+nm2176+nm2180+nm2216+nm2220+nm2408+nm2412+nm2416+nm2424+nm2428+nm2476+nm2480+nm2504+nm2508+nm2512+nm2552+nm2556+nm2560+nm2564+nm2568+nm2572+nm2576+nm2580+nm2584+nm2588+nm2592+nm2596+nm2600+nm2656+nm2660+nm2664, nirs_filtered.data, really.big=F, nvmax=38)
optModelId = which.min(summary(subsets)$cp)
coeffs = coef(subsets, optModelId)
X <- summary(subsets)$which
xvars <- dimnames(X)[[2]][-1]
responsevar <- "N"
id <- X[optModelId,]
name <- as.vector(xvars[which(id[-1])])
form <- reformulate(xvars[which(id[-1])], responsevar, id[1])
mod.nir <- lm(form, nir.data)
nirs_filtered.data
mod.nir <- lm(form, nir.data)
design_mat <- model.matrix(subsets)
design_mat <- model.matrix(subsets)
xvars
X
responsevar
id
form <- reformulate(xvars[which(id[-1])], responsevar, id[1])
mod.nir <- lm(form, nir.data)
mod.nir <- lm(form, nirs_filtered.data)
View(mod.nir)
design_mat <- model.matrix(mod.nir)
X <- summary(subsets)$which
xvars <- dimnames(X)[[2]][-1]
responsevar <- "N"
id <- X[optModelId,]
form <- reformulate(xvars[which(id[-1])], responsevar, id[1])
mod.nir <- lm(form, nirs_filtered.data)
design_mat <- model.matrix(mod.nir)
setwd("~/Dropbox/Studium/Stat. Verfahren/Projekt")
nirs.data <- read.csv("NIR.csv", sep = ";")
# Größe des Datensatztes (Wellenlägen)
dim_nirs_wl <- dim(nirs.data)[2] -3
# Auswahl jeder 5ten Wellenlänge
x = seq(4,322, 5)
nir.data <- nirs.data[,c(2,x)]
require(leaps)
subsets=regsubsets(N~1+nm1980+nm2000+nm2020+nm2100+nm2120+nm2140+nm2160+nm2180+nm2200+nm2220+
nm2240+nm2260+nm2280+nm2380+nm2400+nm2420+nm2440+nm2460+nm2480+nm2500+
nm2520+nm2540+nm2560+nm2580+nm2600+nm2620+nm2640+nm2660, nir.data, really.big=T, nvmax=29)
summary(subsets)$cp
# Save best model
i <- 24 # Index of model in summary
X <- summary(subsets)$which
xvars <- dimnames(X)[[2]][-1]
responsevar <- "N"
id <- X[i,]
name <- as.vector(xvars[which(id[-1])])
form <- reformulate(xvars[which(id[-1])], responsevar, id[1])
mod.nir <- lm(form, nir.data)
#Generierung von Pseudodaten
design_mat <- model.matrix(mod.nir)
View(mod.nir)
View(mod.nir)
View(design_mat)
coeffs = as.vector(coef(subsets, optModelId))
design_mat %*% coeffs
View(mod.nir)
View(mod.nir)
View(design_mat)
View(design_mat)
setwd("~/Dropbox/Studium/Stat. Verfahren/NIR-WS1819/src")
getDiff = function(row, n) {
x=c()
for (i in 1:317) {
x[i] = abs(row[i]-row[i+1])
}
return(x)
}
getDiffMatrix = function(M, rows, cols) {
x1 = getDiff(t(M)[,1], cols)
x2 = getDiff(t(M)[,2], cols)
x=rbind(x1,x2)
for (i in 3:rows) {
x = rbind(x, getDiff(t(M)[,i], cols))
}
return(x)
}
nirs.data = read.csv("../NIR.csv", sep=";")
head(nirs.data)
# nir data only
nir.data = nirs.data[, 4:322]
# wavelengths
x=seq(1400, 2664, 4)
plot(seq(1400, 2672, 4), nir.data[1,], type='l', col=1, ylim=c(0.3,0.7))
lines(seq(1400, 2672, 4), nir.data[2,], type='l', col=2, ylim=c(0.3,0.7))
lines(seq(1400, 2672, 4), nir.data[3,], type='l', col=3, ylim=c(0.3,0.7))
lines(seq(1400, 2672, 4), nir.data[4,], type='l', col=4, ylim=c(0.3,0.7))
lines(seq(1400, 2672, 4), nir.data[5,], type='l', col=5, ylim=c(0.3,0.7))
# plot first deviation for first 6 records
plot(x, getDiff(t(nir.data)[,1], 318), type='l', col=1)
lines(x, getDiff(t(nir.data)[,2], 318), type='l', col=2)
lines(x, getDiff(t(nir.data)[,3], 318), type='l', col=3)
lines(x, getDiff(t(nir.data)[,4], 318), type='l', col=4)
lines(x, getDiff(t(nir.data)[,5], 318), type='l', col=5)
lines(x, getDiff(t(nir.data)[,6], 318), type='l', col=6)
# calculate first deviation for the whole dataset
M = getDiffMatrix(nir.data, 533, 318)
# first deviation average
Mavg = colMeans(M)
plot(x, Mavg, type='l', col=1)
# threshold
THRESHOLD = 0.0015
abline(h=THRESHOLD, col=2)
# filter dataset for colunms having an average value (1. deviation) above threshold
df = data.frame(x, colnames(nirs.data[, 4:320]), Mavg)
colnames(df) = c("x", "nm", "y")
filteredAvg1stDev = subset(df, y >= THRESHOLD, select=c("x", "nm", "y"));
nrow(filteredAvg1stDev)
plot(filteredAvg1stDev$x, filteredAvg1stDev$y, type='p', col=1)
nirs_filtered.data = subset(nirs.data, select=c(c("SOC", "N", "pH"), as.character(filteredAvg1stDev[,"nm"])))
### Mallows CP
require(leaps)
# Select model
subsets = regsubsets( N ~ 1+nm2144+nm2148+nm2152+nm2156+nm2160+nm2164+nm2168+nm2172+nm2176+nm2180+nm2216+nm2220+nm2408+nm2412+nm2416+nm2424+nm2428+nm2476+nm2480+nm2504+nm2508+nm2512+nm2552+nm2556+nm2560+nm2564+nm2568+nm2572+nm2576+nm2580+nm2584+nm2588+nm2592+nm2596+nm2600+nm2656+nm2660+nm2664, nirs_filtered.data, really.big=F, nvmax=39)
optModelId = which.min(summary(subsets)$cp)
coeffs = as.vector(coef(subsets, optModelId))
X <- summary(subsets)$which
xvars <- dimnames(X)[[2]][-1]
responsevar <- "N"
id <- X[optModelId,]
form <- reformulate(xvars[which(id[-1])], responsevar, id[1])
mod.nir <- lm(form, nirs_filtered.data)
design_mat <- model.matrix(mod.nir)
design_mat %*% coeffs
resid_vec <- nirs.data[,2] - mu_vec
mu_vec <- design_mat %*% coeffs
resid_vec <- nirs.data[,2] - mu_vec
sd <- sqrt(as.numeric(t(resid_vec) %*% resid_vec) / dim(nirs.data)[1] - dim(design_mat)[2]))
sd <- sqrt(as.numeric(t(resid_vec) %*% resid_vec / dim(nirs.data)[1] - dim(design_mat)[2]))
dim(nirs.data)[1]
dim(design_mat)[2]))
dim(design_mat)[2]
dim(nirs.data)[1] - dim(design_mat)[2]
t(resid_vec)
resid_vec
resid_vec <- as.vector(nirs.data[,2] - mu_vec)
resid_vec
sd <- sqrt(as.numeric(t(resid_vec) %*% resid_vec / dim(nirs.data)[1] - dim(design_mat)[2]))
t(resid_vec) %*% resid_vec
t(resid_vec) %*% resid_vec / dim(nirs.data)[1] - dim(design_mat)[2]
sd <- sqrt(as.numeric(t(resid_vec) %*% resid_vec / (dim(nirs.data)[1] - dim(design_mat)[2])))
# ##########################################################
# ## SIMULATION
# ##########################################################
getParam = function(colname, data) {
mu_vec <- design_mat %*% coeffs
resid_vec <- as.vector(nirs.data[,2] - mu_vec)
sd <- sqrt(as.numeric(t(resid_vec) %*% resid_vec / (dim(nirs.data)[1] - dim(design_mat)[2])))
}
data = data.frame(matrix(nrow=num, ncol=TIMES));
simulateColumn = function(num, colname, data.origin, TIMES) {
data = data.frame(matrix(nrow=num, ncol=TIMES));
getParam();
for (i in 1:TIMES) {
data[i] = rnorm(num, mean=mu_vec, sd = sd)
}
dataAVG = rowMeans(data)
return(dataAVG)
}
simulateDataset = function(numRows, coeffs, data.origin, TIMES) {
sim.data = data.frame(matrix(nrow=numRows));
# simulate nir data
for (feature in colnames(data.origin)[-1:-3]) {
sim.data[,feature] = simulateColumn(numRows, feature, data.origin, TIMES)
}
# use estimated coefficients to calculate value for N
sim.data$N = as.vector(coeffs)[1];
for (feature in names(coeffs[-1])) {
sim.data$N = sim.data$N + coeffs[feature] + sim.data[,feature]
}
return(sim.data[,-1])
}
set.seed(13)
simdata = simulateDataset(30, coeffs, nirs.data, 100);
simdata
